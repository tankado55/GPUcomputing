{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[{"file_id":"13cE4WVhV6a7Slj76dUC_hirmu_YZoF4b","timestamp":1683545776293}],"collapsed_sections":["WoJbB3T5Vkw-","_cGSqZovVkxK","zs_a5Vuimily","iUYP4kCJhEIx","sEN7QQnSxNca","vXUIQkZLCTcG","O2AFWRhsw2XO"],"mount_file_id":"1mk0QXjREp-k_J-pdFfmgoC7-EVmgPyAo","authorship_tag":"ABX9TyN+6/Mkeg33Gd+rTMZuuoQU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["---\n","# **LAB 9 - CUDA Libraries**\n","---"],"metadata":{"id":"fZYqN0UwVLC_"}},{"cell_type":"markdown","metadata":{"id":"WoJbB3T5Vkw-"},"source":["# ▶️ CUDA setup"]},{"cell_type":"code","metadata":{"id":"Fht2Wy8wVkxJ"},"source":["!nvcc --version"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0jP2H_YJVkxJ"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## [GPU Compute Capability](https://developer.nvidia.com/cuda-gpus)"],"metadata":{"id":"VKbaxH9wWosO"}},{"cell_type":"markdown","metadata":{"id":"_cGSqZovVkxK"},"source":["## NVCC Plugin for Jupyter notebook\n","\n","*Usage*:\n","\n","\n","*   Load Extension `%load_ext nvcc_plugin`\n","*   Mark a cell to be treated as cuda cell\n","`%%cuda --name example.cu --compile false`\n","\n","**NOTE**: The cell must contain either code or comments to be run successfully. It accepts 2 arguments. `-n | --name` - which is the name of either CUDA source or Header. The name parameter must have extension `.cu` or `.h`. Second argument -c | --compile; default value is false. The argument is a flag to specify if the cell will be compiled and run right away or not. It might be usefull if you're playing in the main function\n","\n","*  We are ready to run CUDA C/C++ code right in your Notebook. For this we need explicitly say to the interpreter, that we want to use the extension by adding `%%cu` at the beginning of each cell with CUDA code. \n","\n","\n"]},{"cell_type":"code","metadata":{"id":"RCVhMkqYVkxK"},"source":["!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e6PDOytTVkxK"},"source":["%load_ext nvcc_plugin"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Clone GPUcomputing site on github..."],"metadata":{"id":"IYG8Cv4bTzyI"}},{"cell_type":"code","source":["!git clone https://github.com/giulianogrossi/GPUcomputing.git"],"metadata":{"id":"E7jZmHjCT0vu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# ▶️ VS Code on Colab"],"metadata":{"id":"zs_a5Vuimily"}},{"cell_type":"code","source":["#@title Colab-ssh tunnel\n","#@markdown Execute this cell to open the ssh tunnel. Check [colab-ssh documentation](https://github.com/WassimBenzarti/colab-ssh) for more details.\n","\n","# Install colab_ssh on google colab\n","!pip install colab_ssh --upgrade\n","\n","from colab_ssh import launch_ssh_cloudflared, init_git_cloudflared\n","ssh_tunnel_password = \"gpu\" #@param {type: \"string\"}\n","launch_ssh_cloudflared(password=ssh_tunnel_password)\n","\n","# Optional: if you want to clone a Github or Gitlab repository\n","repository_url=\"https://github.com/giulianogrossi/GPUcomputing\" #@param {type: \"string\"}\n","init_git_cloudflared(repository_url)"],"metadata":{"id":"BCf9JxqphHAp","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iUYP4kCJhEIx"},"source":["# ▶️ DeviceQuery"]},{"cell_type":"code","metadata":{"id":"kW9b_Yuxi7id"},"source":["# DeviceQuery dell'attuale device (su Colab!)\n","!nvcc /content/GPUcomputing/utils/deviceQuery.cu -o deviceQuery\n","!./deviceQuery"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Check whether the device can transfer in both directions simultaneously"],"metadata":{"id":"J-EcbVrAYlfS"}},{"cell_type":"code","source":["%%cu\n","#include <stdio.h>\n","\n","int main(void) {\n","\n","  cudaDeviceProp dProp;\n","\tcudaGetDeviceProperties(&dProp, 0);\n","\n","  // Shows whether the device can transfer in both directions simultaneously\n","  printf(\"Device %s capable of simultaneous CPU-to-GPU and GPU-to-CPU datatransfers\\n\", dProp.deviceOverlap ? \"IS\": \"NOT\");\n","  return 0;\n","}"],"metadata":{"id":"esYDQTl-Yg3B"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lAVvcKOX_DU0"},"source":["# ✅ cuBLAS"]},{"cell_type":"code","metadata":{"id":"OH6TuWnB-_0M"},"source":["%%cuda --name mat_prod_cublas.cu\n","\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include \"cublas_v2.h\"\n","#include \"../GPUcomputing/utils/common.h\"\n","\n","#define IDX2R(r,c,D) ( r * D + c) \n","#define IDX2C(r,c,D) ( c * D + r )\n","\n","#define BLOCK_SIZE 4\n","#define M          (1<<12)\n","#define N          (1<<12)\n","#define P          (1<<12)\n","\n","void generate_random_vector(int, float**);\n","void generate_random_dense_matrix_Row_Maj(int, int, float**);\n","void generate_random_dense_matrix_Col_Maj(int, int, float**);\n","void plot_mat_Row_Maj(int, int, float*, char);\n","void plot_mat_Col_Maj(int, int, float*, char);\n","__global__ void matProdSMEMstatic(float*, float*, float*, int, int, int);\n","\n","/*\n"," * comparison between standard prod kernel and cuBLAS\n"," */\n","int main(int argc, char **argv) {\n","\n","\tint n = N, m = M, p = P;\n","\tfloat *A, *d_A;  // matrix M x N  (row M, col N)\n","\tfloat *B, *d_B;  // matrix N x P  (row N, col P)\n","\tfloat *C, *d_C;  // matrix M x P, C = A*B\n","\tfloat *x, *d_x;  // vector N x 1 \n","\tfloat *y, *d_y;  // vector N x 1, y = A*x\n","\tfloat beta = 0.0f;\n","\tfloat alpha = 1.0f;\n","\tcublasHandle_t handle;\n","\tdevice_name();\n","\n","\t// events to measure time\n","\tcudaEvent_t start, stop;\n","\tcudaEventCreate(&start);\n","\tcudaEventCreate(&stop);\n","\n","\t// Generate inputs\n","\tsrand(10);\n","\tgenerate_random_dense_matrix_Col_Maj(m, n, &A);\n","\tgenerate_random_dense_matrix_Col_Maj(n, p, &B);\n","\tgenerate_random_vector(n, &x);\n","\tgenerate_random_vector(n, &y);\n","\n","\tC = (float *) malloc(m * p * sizeof(float));\n","\n","\t// Allocate device memory\n","\tCHECK(cudaMalloc((void **)&d_A, m * n * sizeof(float)));\n","\tCHECK(cudaMalloc((void **)&d_B, n * p * sizeof(float)));\n","\tCHECK(cudaMalloc((void **)&d_C, m * p * sizeof(float)));\n","\tCHECK(cudaMalloc((void **)&d_x, n * sizeof(float)));\n","\tCHECK(cudaMalloc((void **)&d_y, m * sizeof(float)));\n","\n","\t// Create the cuBLAS handle\n","\tCHECK_CUBLAS(cublasCreate(&handle));\n","\tint version;\n","\tCHECK_CUBLAS(cublasGetVersion(handle, &version));\n","\tprintf(\"Using CUBLAS Version: %d\\n\", version);\n","\t\n","\t// Transfer inputs to the device, column-major order\n","\tCHECK_CUBLAS(cublasSetMatrix(m, n, sizeof(float), A, m, d_A, m));\n","\tCHECK_CUBLAS(cublasSetMatrix(n, p, sizeof(float), B, n, d_B, n));\n","\tCHECK_CUBLAS(cublasSetMatrix(m, p, sizeof(float), C, m, d_C, m));\n","\tCHECK_CUBLAS(cublasSetVector(n, sizeof(float), x, 1, d_x, 1));\n","\tCHECK_CUBLAS(cublasSetVector(m, sizeof(float), y, 1, d_y, 1));\n","\n","\t/***************************************************\n","\t *      Multipl. matrix-vector CUBLAS              *\n","\t ***************************************************/\n","\t\n","  printf(\"\\n**  Matrix-vector product...\\n\");\n","  printf(\"    y(%d x 1) = A(%d x %d) * x(%d x 1)\\n\",n,m,n,n);\n","\n","\tcudaEventRecord(start);\n","\tCHECK_CUBLAS(cublasSgemv(handle, CUBLAS_OP_N, m, n, &alpha, d_A, m, d_x, 1, &beta, d_y, 1));\n","\tcudaEventRecord(stop);\n","\tcudaEventSynchronize(stop);\n","\tfloat milliseconds;\n","\tcudaEventElapsedTime(&milliseconds, start, stop);\n","\tprintf(\"    elapsed time: %.5f (sec)\\n\", milliseconds / 1000.0);\n","\n","\t// Retrieve the output vector from the device\n","\tCHECK_CUBLAS(cublasGetVector(m, sizeof(float), d_y, 1, y, 1));\n","\n","\n","\t/**********************************************\n","\t *  Multiplic. matrix-matrix CUBLAS           *\n","\t **********************************************/\n","\n","\tprintf(\"\\n**  Matrix-Matrix product...\\n\");\n","  printf(\"    C(%d x %d) = A(%d x %d) * B(%d x %d)\\n\",m,p,m,n,n,p);\n","\n","  //plot_mat_Col_Maj(m, n, A, 'A');\n","  //plot_mat_Col_Maj(n, p, B, 'B');\n","\n","\tCHECK(cudaMemset(d_C, 0,  m * p *sizeof(float)));\n","\tCHECK(cudaEventRecord(start));\n","\tCHECK_CUBLAS(cublasSgemm(handle, CUBLAS_OP_N, CUBLAS_OP_N, m, p, n, &alpha, d_A, m, d_B, n, &beta, d_C, m));\n","\tCHECK(cudaEventRecord(stop));\n","\tCHECK(cudaEventSynchronize(stop));\n","\tCHECK(cudaEventElapsedTime(&milliseconds, start, stop));\n","\tprintf(\"    elapsed time: %.5f (sec)\\n\", milliseconds / 1000.0);\n","\n","\t// Retrieve the output vector from the device\n","\tCHECK_CUBLAS(cublasGetMatrix(m, p, sizeof(float), d_C, m, C, m));\n","\n","  //plot_mat_Col_Maj(m, p, C, 'C');\n","\n","\n","\t/*****************************************************\n","\t *  Multiplicat. matrix-matrix kernel ad-hoc         *\n","\t *****************************************************/\n","\n","\tprintf(\"\\n**  Matrix-Matrix product using ad-hoc kernel (with SMEM)...\\n\");\n","  printf(\"    C(%d x %d) = A(%d x %d) * B(%d x %d)\\n\",m,p,m,n,n,p);\n","  \n","  float *A1, *B1; \n","  srand(10);\n","\tgenerate_random_dense_matrix_Row_Maj(m, n, &A1);\n","\tgenerate_random_dense_matrix_Row_Maj(n, p, &B1);\n","\n","  //plot_mat_Row_Maj(m, n, A1, 'A');\n","  //plot_mat_Row_Maj(n, p, B1, 'B');\n","\n","\t// copy matrices A and B to the GPU\n","\tCHECK(cudaMemcpy(d_A, A1, m * n * sizeof(float), cudaMemcpyHostToDevice));\n","\tCHECK(cudaMemcpy(d_B, B1, n * p * sizeof(float), cudaMemcpyHostToDevice));\n","  CHECK(cudaMemset(d_C, 0.0f, m * p * sizeof(float)));\n","\n","\t// grid block dims = shared mem dims = BLOCK_SIZE\n","\tdim3 block(BLOCK_SIZE, BLOCK_SIZE);\n","\tdim3 grid((p + block.x - 1) / block.x, (m + block.y - 1) / block.y);\n","\tCHECK(cudaEventRecord(start));\n","\tmatProdSMEMstatic<<<grid, block>>>(d_A, d_B, d_C, n, m, p);\n","  CHECK(cudaDeviceSynchronize());\n","\tCHECK(cudaEventRecord(stop));\n","\tCHECK(cudaEventSynchronize(stop));\n","\tCHECK(cudaEventElapsedTime(&milliseconds, start, stop));\n","\tprintf(\"    elapsed time: %.5f (sec)\\n\", milliseconds / 1000.0);\n","\n","\t// copy the array 'C' back from the GPU to the CPU\n","\tCHECK(cudaMemcpy(C, d_C, m * p * sizeof(float), cudaMemcpyDeviceToHost));\n","\n","  //plot_mat_Row_Maj(m, p, C, 'C');\n","  \n","\t// free memory\n","\tcudaFree(d_A);\n","\tcudaFree(d_B);\n","\tcudaFree(d_C);\n","\tcudaFree(d_x);\n","\tcudaFree(d_y);\n","\tCHECK_CUBLAS(cublasDestroy(handle));\n","\n","\treturn EXIT_SUCCESS;\n","}\n","\n","/*\n"," * Generate a vector of length N with random single-precision floating-point\n"," * values between 0 and 100.\n"," */\n","\n","void generate_random_vector(int n, float **x) {\n","\tfloat *z = (float *) malloc(sizeof(float) * n);\n","\n","\tfor (int i = 0; i < n; i++)\n","\t\tz[i] = (float)rand() / RAND_MAX;\n","\t*x = z;\n","}\n","\n","/*\n"," * Generate a matrix with M rows and N columns in column-major order. The matrix\n"," * will be filled with random single-precision floating-point values between 0 and 10\n"," */\n","void generate_random_dense_matrix_Col_Maj(int rows, int cols, float **A) {\n","\tfloat *a = (float *) malloc(sizeof(float) * rows * cols);\n","\n","  float val = 1.0;\n","  for (int c = 0; c < cols; ++c)\n","    for (int r = 0; r < rows; ++r){\n","      a[IDX2C(r,c,rows)] = val;\n","      val += 1;\n","    }\n","\t*A = a;\n","}\n","\n","void generate_random_dense_matrix_Row_Maj(int rows, int cols, float **A) {\n","\tfloat *a = (float *) malloc(sizeof(float) * rows * cols);\n","\n","  float val = 1.0;\n","\tfor (int r = 0; r < rows; r++)\n","\t\tfor (int c = 0; c < cols; c++) {\n","\t\t\ta[IDX2R(r,c,cols)] = val;\n","      val += 1;\n","\t\t}\n","\t*A = a;\n","}\n","\n","void plot_mat_Row_Maj(int rows, int cols, float *A, char name) {\n","  printf(\"\\nShow mat %c...\\n\", name);\n","\tfor(int r = 0; r < rows; ++r){\n","    for(int c = 0; c < cols; ++c)\n","\t\t\tprintf(\"%4.1f \", A[IDX2R(r,c,cols)]);\n","    printf(\"\\n\");\n","\t} \n","  printf(\"\\n\");\n","}\n","\n","void plot_mat_Col_Maj(int rows, int cols, float *A, char name) {\n","  printf(\"\\nShow mat %c...\\n\", name);\n","  for(int r = 0; r < rows; ++r){\n","    for(int c = 0; c < cols; ++c)\n","      printf(\"%4.1f \", A[IDX2C(r,c,rows)]);\n","    printf(\"\\n\");\n","  }\n","  printf(\"\\n\");\n","}\n","\n","\n","/*\n"," * Kernel for matrix product with static SMEM\n"," *      C   =   A   *   B\n"," *   (m x p) (m x n) (n x p)\n"," */\n","__global__ void matProdSMEMstatic(float* A, float* B, float* C, int n, int m, int p) {\n","\t// indexes\n","\tuint row = blockIdx.y * blockDim.y + threadIdx.y; // in [0..m]\n","\tuint col = blockIdx.x * blockDim.x + threadIdx.x; // in [0..p]\n","\n","\t// target: compute the right sum for the given row and col\n","\tfloat sum = 0.0;\n","\n","\t// static shared memory\n","\t__shared__ float As[BLOCK_SIZE][BLOCK_SIZE];\n","\t__shared__ float Bs[BLOCK_SIZE][BLOCK_SIZE];\n","\n","\t// loop over blocks from block row of matrix A and block column of matrix B\n","\tuint numBlocks = (n + BLOCK_SIZE - 1) / BLOCK_SIZE;\n","\n","\tfor (uint i = 0; i < numBlocks; i++) {\n","\n","\t\t// copy block from matrix to shared memory\n","\t\tuint r = i * BLOCK_SIZE + threadIdx.y;\n","\t\tuint c = i * BLOCK_SIZE + threadIdx.x;\n","\t\tAs[threadIdx.y][threadIdx.x] = A[IDX2R(row, c, n)];\n","\t\tBs[threadIdx.y][threadIdx.x] = B[IDX2R(r, col, p)];\n","\n","\t\t__syncthreads();  //  BARRIER SYNC on SMEM loading\n","\n","\t\tuint K = BLOCK_SIZE;\n","\t\tif (i == (numBlocks - 1)) \n","      K = n - i * BLOCK_SIZE;   // tune last block\n","\n","\t\t// compute this part of row-column product\n","\t\tfor (uint k = 0; k < K; k++)\n","\t\t\tsum += As[threadIdx.y][k] * Bs[k][threadIdx.x];\n","\n","\t\t__syncthreads();  //  BARRIER SYNC on prod over blocks\n","\t}\n","\n","\t// store computed element in matrix C\n","\tif (row < m && col < p)\n","\t\tC[row * p + col] = sum;\n","}\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7G91KROXBScK"},"source":["# Compilazione ed esecuzione\n","\n","!nvcc -arch=sm_75 src/mat_prod_cublas.cu  -o prod -lcublas\n","!./prod"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 🔴 TODO"],"metadata":{"id":"sEN7QQnSxNca"}},{"cell_type":"code","source":["%%cuda --name conj_grad.cu\n","\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <string.h>\n","#include <time.h>\n","#include <cublas_v2.h>\n","#include <cuda_runtime.h>\n","#include <cusparse.h>\n","#include \"../GPUcomputing/utils/common.h\"\n","\n","#define IDX2R(r,c,D) ( r * D + c) \n","#define IDX2C(r,c,D) ( c * D + r )\n","\n","#define N          (1<<10)\n","\n","void generate_random_vector(int, double**);\n","void generate_rand_posdefinite_mat(int, double**);\n","void plot_mat(int, double*, char);\n","void plot_vec(int, double*, char); \n","double norm2(int, double *);\n","\n","/*\n"," * This sample implements a conjugate gradient solver on GPU using CUBLAS\n"," */\n","int main(int argc, char **argv) {\n","  int n = N;\n","\tdouble *A, *dA;      // matrix N x N  (square)\n","\tdouble *x, *dx;      // vector N x 1 \n","\tdouble *b, *db;      // vector N x 1\n","\tdouble *dr, *dr1;    // vector N x 1\n","\tdouble *dp;          // vector N x 1\n","\tdouble *dAxp, *dAxr; // vector N x 1\n","\t\n","\tcublasHandle_t handle;\n","\tdevice_name();\n","\n","\t// events to measure time\n","\tcudaEvent_t start, stop;\n","\tcudaEventCreate(&start);\n","\tcudaEventCreate(&stop);\n","\n","\t// Generate instance: matrix A and vector b\n","\tsrand(time(NULL));\n","\tgenerate_rand_posdefinite_mat(n, &A);      // random symmetric matrix A\n","\tgenerate_random_vector(n, &b);            // random verctor b\n","\tgenerate_random_vector(n, &x);            // random initial solution\n","\t//plot_mat(n, A,'A');\n","\n","\t// Allocate device memory\n","\tCHECK(cudaMalloc((void **)&dA, n * n * sizeof(double)));\n","\tCHECK(cudaMalloc((void **)&dx, n * sizeof(double)));\n","\tCHECK(cudaMalloc((void **)&db, n * sizeof(double)));\n","\tCHECK(cudaMalloc((void **)&dr, n * sizeof(double)));\n","\tCHECK(cudaMalloc((void **)&dr1, n * sizeof(double)));\n","\tCHECK(cudaMalloc((void **)&dp, n * sizeof(double)));\n","\tCHECK(cudaMalloc((void **)&dAxp, n * sizeof(double)));\n","\tCHECK(cudaMalloc((void **)&dAxr, n * sizeof(double)));\n","\n","\t// Create the cuBLAS handle\n","\tCHECK_CUBLAS(cublasCreate(&handle));\n","\tint version;\n","\tCHECK_CUBLAS(cublasGetVersion(handle, &version));\n","\tprintf(\"Using CUBLAS Version: %d\\n\", version);\n","\t\n","\t// Transfer inputs to the device, column-major order\n","\tCHECK_CUBLAS(cublasSetMatrix(n, n, sizeof(double), A, n, dA, n));\n","\tCHECK_CUBLAS(cublasSetVector(n, sizeof(double), b, 1, db, 1));\n","\tCHECK_CUBLAS(cublasSetVector(n, sizeof(double), x, 1, dx, 1));\n","\n","\t// CG\n","\tdouble beta = 0.0f;\n","\tdouble alpha = 0.0f;\n","\tdouble one = 1.0f, minusOne = -1.0f, zero = 0.0f;\n","\tdouble num, den = 0, tmp;\n","\tint k = 0, maxit = 2000;\n","                        //# r0 = b\n","\t\t\t\t\t\t\t\t\t\t\t\t//# r0 = b − 𝐴∗x0\n","\t                      //# p0 = r0\n","\t\t                    //# p𝑘^𝑇 ∗ r𝑘 (num)\n","\t\t\t\t\t\t\t\t\t\t   \t//# 𝐴 ∗ p𝑘    \n","\t\t\t               \t //# p𝑘^𝑇 ∗ 𝐴 ∗ p𝑘  (den)\n","\t\t\t                 //# 𝛼𝑘 = num/den\n","\t\t\t                 //# x(𝑘+1) = x𝑘 + 𝛼𝑘 * p𝑘\n","\t\t\t                //# r(𝑘+1) = b − 𝛼𝑘 * 𝐴 ∗ p𝑘\n","\t\t\t\t\t\t\t\t  \t\t//# 𝐴 ∗ r(𝑘+1)     \n","\t\t\t                //# p𝑘^𝑇 ∗ 𝐴 ∗ r(𝑘+1)  (num)\n","\t\t\t                //# 𝛽𝑘 = num/den\n","\t\t\t                 //# r1 = r(𝑘+1)\n","\t\t\t               \t//# r1 = r1 - 𝛽𝑘 * p𝑘\n","\t\t\t               \t //# p(𝑘+1) = r(𝑘+1) - 𝛽𝑘 * p𝑘\n","\t\t\n","\n","\n","\t// final solution\n","\tdouble *y = (double *) malloc(sizeof(double) * n);\n","\tCHECK_CUBLAS(cublasGetVector(n, sizeof(double), dx, 1, x, 1));\n","\tcublasDgemv(handle, CUBLAS_OP_N, n, n, &one, dA, n, dx, 1, &zero, db, 1);   // b = 𝐴∗𝑥 \n","\tCHECK_CUBLAS(cublasGetVector(n, sizeof(double), db, 1, y, 1));                // y = b (approx solution)\n","\n","\t//plot norms of the vectors\n","\tprintf(\"norm b = %f\\n\", norm2(n, b));   \n","\tprintf(\"norm y = %f\\n\", norm2(n, y));   \n","\t//plot_vec(n, b, 'b');\n","\t//plot_vec(n, y, 'y');\n","\n","  free(A);\n","  free(x);\n","  free(b);\n","  cudaFree(dA);\n","  cudaFree(dx);\n","\tcudaFree(db);\n","  cudaFree(dr);\n","\tcudaFree(dr1);\n","\tcudaFree(dp);\n","\tcudaFree(dAxp);\n","\tcudaFree(dAxr);\n","}\n","\n","void generate_rand_posdefinite_mat(int n, double **A) {\n","\tdouble *a = (double *) malloc(sizeof(double) * n * n);\n","\tdouble *r = (double *) malloc(sizeof(double) * n * n);\n","\n","\t// generate a random matrix\n","\tfor (int i = 0; i < n; i++)\n","\t\tfor (int j = 0; j < n; j++) \n","\t\t\tr[i*n+j] = (double)rand() / RAND_MAX;\n","\t\t\n","\t// compute the product with its transpose (positive definite matrix)\n","\tfor (int i = 0; i < n; i++)\n","  \tfor (int j = i; j < n; j++) {\n","   \t\ta[i*n+j] = 0;\n","   \t\tfor (int k = 0; k < n; k++) \n","    \t\ta[i*n+j] += r[i*n+k]*r[j*n+k];\n","\t\t\ta[j*n+i] = a[i*n+j];\n","  \t}\n","\t*A = a;\n","}\n","\n","void plot_mat(int n, double *A, char name) {\n","  printf(\"\\nShow mat %c...\\n\", name);\n","\tfor(int r = 0; r < n; ++r){\n","    for(int c = 0; c < n; ++c)\n","\t\t\tprintf(\"%4.1f \", A[IDX2R(r,c,n)]);\n","    printf(\"\\n\");\n","\t} \n","  printf(\"\\n\");\n","}\n","\n","double norm2(int n, double *x) {\n","\tdouble norm = 0;\n","\tfor(int i = 0; i < n; ++i)\n","\t\tnorm += x[i]*x[i];\n","\tnorm = sqrt(norm);\n","  return norm; \n","}\n","\n","void plot_vec(int n, double *x, char name) {\n","  printf(\"\\nShow vec %c...\\n\", name);\n","\tfor(int i = 0; i < n; ++i)\n","\t\t\tprintf(\"%4.1f \", x[i]);\n","  printf(\"\\n\");\n","}\n","\n","void generate_random_vector(int n, double **x) {\n","\tdouble *z = (double *) malloc(sizeof(double) * n);\n","\n","\tfor (int i = 0; i < n; i++)\n","\t\tz[i] = (double)rand() / RAND_MAX;\n","\t*x = z;\n","}"],"metadata":{"id":"i5zDpZBgxOeO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Compilazione ed esecuzione\n","\n","!nvcc -arch=sm_75 src/conj_grad.cu  -o CG -lcublas\n","!./CG"],"metadata":{"id":"5BZPf-gK0kJo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vXUIQkZLCTcG"},"source":["# ✅ cuRAND\n"]},{"cell_type":"code","metadata":{"id":"-Y52R0d3CA50"},"source":["%%cuda --name PI_kernel_MC.cu\n","\n","#include <stdio.h>\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <cuda.h>\n","#include <curand_kernel.h>\n","#include \"../GPUcomputing/utils/common.h\"\n","\n","\n","#define TRIALS_PER_THREAD 10000\n","#define BLOCKS  264\n","#define THREADS 264\n","#define PI 3.1415926535 // known value of pi\n","\n","float pi_mc_CPU(long trials) {\n","\tlong points_in_circle = 0;\n","\tfor (long i = 0; i < trials; i++) {\n","\t\tfloat x = rand() / (float) RAND_MAX;\n","\t\tfloat y = rand() / (float) RAND_MAX;\n","\t\tpoints_in_circle += (x * x + y * y <= 1.0f);\n","\t}\n","\treturn 4.0f * points_in_circle / trials;\n","}\n","\n","__global__ void pi_mc_GPU(float *estimate, curandState *states) {\n","\tunsigned int tid = threadIdx.x + blockDim.x * blockIdx.x;\n","\tint points_in_circle = 0;\n","\tcurand_init(tid, 0, 0, &states[tid]);\n","\tfor (int i = 0; i < TRIALS_PER_THREAD; i++) {\n","\t\tfloat x = curand_uniform(&states[tid]);\n","\t\tfloat y = curand_uniform(&states[tid]);\n","\t\tpoints_in_circle += (x * x + y * y <= 1.0f);\n","\t}\n","\testimate[tid] = 4.0f * points_in_circle / (float) TRIALS_PER_THREAD;\n","}\n","\n","/*\n"," * MAIN: MC method\n"," */\n","int main(void) {\n","\n","\tfloat host[BLOCKS * THREADS];\n","\tfloat *dev;\n","\n","\t// events to measure time\n","\tcudaEvent_t start, stop;\n","\tcudaEventCreate(&start);\n","\tcudaEventCreate(&stop);\n","\n","\t// CPU procedure\n","\tfloat iStart = seconds();\n","\tfloat pi_cpu = pi_mc_CPU(THREADS * BLOCKS * TRIALS_PER_THREAD);\n","\tfloat iElaps = seconds() - iStart;\n","\tprintf(\"CPU elapsed time: %.5f (sec)\\n\", iElaps);\n","\tprintf(\"CPU estimate of PI = %f [error of %f]\\n\", pi_cpu, abs(pi_cpu - PI));\n","\n","\t// GPU procedure\n","\tcurandState *devStates;\n","\tcudaMalloc((void **) &dev, BLOCKS * THREADS * sizeof(float));\n","\tcudaMalloc((void **) &devStates, BLOCKS * THREADS * sizeof(curandState));\n","\tcudaEventRecord(start);\n","\tpi_mc_GPU<<<BLOCKS, THREADS>>>(dev, devStates);\n","  cudaEventRecord(stop);\n","\tcudaEventSynchronize(stop);\n","\tcudaMemcpy(host, dev, BLOCKS * THREADS * sizeof(float), cudaMemcpyDeviceToHost);\n","\tfloat pi_gpu = 0.0;\n","\tfor (int i = 0; i < BLOCKS * THREADS; i++)\n","\t\tpi_gpu += host[i];\n","\tpi_gpu /= (BLOCKS * THREADS);\n","\tfloat milliseconds = 0;\n","\tcudaEventElapsedTime(&milliseconds, start, stop);\n","\tprintf(\"\\nGPU elapsed time (curand Monte Carlo): %.5f (sec)\\n\", milliseconds / 1000);\n","\tprintf(\"GPU estimate of PI = %f [error of %f ]\\n\", pi_gpu, abs(pi_gpu - PI));\n","  printf(\"Speed-up           = %.0f\\n\", iElaps/milliseconds*1000);\n","\tcudaFree(dev);\n","\tcudaFree(devStates);\n","\treturn 0;\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0PSc9B9PDTWt"},"source":["# Compilazione ed esecuzione\n","\n","!nvcc -arch=sm_75 src/PI_kernel_MC.cu  -o mc_PI\n","!./mc_PI"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eLcGSW8rqa9j"},"source":["%%cuda --name PI_host_MC.cu\n","\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <curand.h>\n","#include \"../GPUcomputing/utils/common.h\"\n","\n","#define TRIALS_PER_THREAD 10000\n","#define BLOCKS  264\n","#define THREADS 264\n","#define PI 3.1415926535 // known value of pi\n","\n","int main(void) {\n","    \n","\tlong trials = THREADS * BLOCKS * TRIALS_PER_THREAD; // num points\n","\n","  printf(\"Number of random points in the square = %lu\\n\", trials);\n","\n","\tcurandGenerator_t gen;\n","\tfloat *X_d, *X, *Y_d, *Y ;\n","\n","\t// Allocate points on host\n","\tX = (float *) malloc(trials * sizeof(float));\n","  Y = (float *) malloc(trials * sizeof(float));\n","\n","\t/* Allocate n floats on device */\n","\tCHECK(cudaMalloc((void **)&X_d, trials * sizeof(float)));\n","  CHECK(cudaMalloc((void **)&Y_d, trials * sizeof(float)));\n","\n","\t// Create pseudo-random number generator \n","\tCHECK_CURAND(curandCreateGenerator(&gen, CURAND_RNG_PSEUDO_DEFAULT));\n","\n","\t// Set seed \n","\tCHECK_CURAND(curandSetPseudoRandomGeneratorSeed(gen, 1234ULL));\n","\n","\t// Generate 2*n floats on device \n","\tCHECK_CURAND(curandGenerateUniform(gen, X_d, trials));\n","  CHECK_CURAND(curandGenerateUniform(gen, Y_d, trials));\n","\n","\t// Copy device memory to host \n","\tCHECK(cudaMemcpy(X, X_d, trials * sizeof(float), cudaMemcpyDeviceToHost));\n","  CHECK(cudaMemcpy(Y, Y_d, trials * sizeof(float), cudaMemcpyDeviceToHost));\n","\n","  // num of points within the circle\n","  ulong points_in_circle = 0;\n","  for (long i = 0; i < trials; i++) \n","\t\tpoints_in_circle += (X[i] * X[i] + Y[i] * Y[i] <= 1.0f);\n","\n","  // estimate PI\n","\tfloat pi = 4.0f * points_in_circle / (float)trials;\n","  printf(\"Estimate of PI = %f [error of %f]\\n\", pi, abs(pi - PI));\n","\n","\t// Cleanup \n","\tCHECK_CURAND(curandDestroyGenerator(gen));\n","\tCHECK(cudaFree(X_d));\n","  CHECK(cudaFree(Y_d));\n","  free(X);\n","\tfree(Y);\n","\treturn EXIT_SUCCESS;\n","}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mfR471rze2p-"},"source":["# Compilazione ed esecuzione\n","\n","!nvcc -arch=sm_75 src/PI_host_MC.cu -o mc_PI -lcurand\n","!./mc_PI"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 🔴 TODO"],"metadata":{"id":"O2AFWRhsw2XO"}},{"cell_type":"code","metadata":{"id":"UcVvtvNN3-3V"},"source":["%%cuda --name Gauss_MC.cu\n","\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <cuda.h>\n","#include <curand_kernel.h>\n","#include \"../GPUcomputing/utils/common.h\"\n","\n","#define TRIALS_PER_THREAD 10000\n","#define BLOCKS  264\n","#define THREADS 264\n","#define PI 3.1415926535 // known value of pi\n","\n","float Gauss_CPU(long trials, float a, float b, float max) {\n","\tlong s = 0;\n","\tfor (long i = 0; i < trials; i++) {\n","\t\tfloat x = (b-a)*(rand() / (float) RAND_MAX)+a;\n","\t\tfloat y = (rand() / (float) RAND_MAX);\n","\t\ts += (y <= expf(-x*x/2));\n","\t}\n","\treturn s / (float)trials;\n","}\n","\n","__global__ void Gauss_GPU() {\n","\t//# TODO\n","}\n","\n","int main(int argc, char *argv[]) {\n","\n","\tfloat host[BLOCKS * THREADS];\n","\tfloat *dev;\n","\tfloat a = -1;\n","\tfloat b = 2;\n","\tfloat max = 1.0f/sqrt(2*PI);\n","\tfloat A = (b-a)*max;\n","\tfloat P_true = 0.818594;\n","\n","\t// events to measure time\n","\tcudaEvent_t start, stop;\n","\tcudaEventCreate(&start);\n","\tcudaEventCreate(&stop);\n","\n","\t// CPU procedure\n","\tfloat iStart = seconds();\n","\tlong N = THREADS * BLOCKS * TRIALS_PER_THREAD;\n","\tfloat P_cpu = Gauss_CPU(N,a,b,max);\n","\tfloat iElaps = seconds() - iStart;\n","\tP_cpu = P_cpu*A;\n","\tprintf(\"CPU elapsed time: %.5f (sec)\\n\", iElaps);\n","\tprintf(\"CPU estimate of P = %f [error of %f]\\n\", P_cpu, abs(P_cpu - P_true));\n","\n","\t// GPU procedure\n","\t\n","\t//# TODO\n","\n","\t\n","\tprintf(\"GPU elapsed time: %.5f (sec)\\n\", seconds);\n","\tprintf(\"GPU estimate of P = %f [error of %f ]\\n\", P, abs(P - P_true));\n","\tprintf(\"Speedup = %f\\n\", iElaps/seconds);\n","\tcudaFree(dev);\n","\tcudaFree(devStates);\n","\treturn 0;\n","}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nCLXnW_34NPf"},"source":["# Compilazione ed esecuzione\n","\n","!nvcc -arch=sm_75 src/Gauss_MC.cu -o Gauss_MC\n","!./Gauss_MC"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SOFMQZAkjlLW"},"source":["# ✅ cuFFT"]},{"cell_type":"code","metadata":{"id":"v9nRkLgeB10A"},"source":["%%cuda --name cufft.cu\n","\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <cufft.h>\n","#include \"../GPUcomputing/utils/common.h\"\n","\n","#define BATCH 16\n","\n","/*\n"," * An example usage of the cuFFT library. This example performs a 1D forward\n"," * FFT.\n"," */\n","\n","int nprints = 30;\n","\n","/*\n"," * Create N fake samplings along the function cos(x). These samplings will be\n"," * stored as single-precision floating-point values.\n"," */\n","void generate_fake_samples(int N, float **out) {\n","\tint i;\n","\tfloat *result = (float *) malloc(sizeof(float) * N);\n","\tfloat delta = M_PI / 20.0;\n","\tfor (i = 0; i < N; i++)\n","\t\tresult[i] = cos(i * delta);\n","\t*out = result;\n","}\n","\n","void rect(uint N, float **out) {\n","\tfloat *r = (float *) calloc(N, sizeof(float));\n","\tfor (uint i = 0; i < N/100; ++i) \n","    r[i] = 1.0f;\n","\t*out = r;\n","}\n","\n","/*\n"," * Convert a real-valued vector r of length Nto a complex-valued vector.\n"," */\n","void real_to_complex(float *r, cufftComplex **complx, int N) {\n","\tint i;\n","\t(*complx) = (cufftComplex *) malloc(sizeof(cufftComplex) * N);\n","\n","\tfor (i = 0; i < N; i++) {\n","\t\t(*complx)[i].x = r[i];\n","\t\t(*complx)[i].y = 0;\n","\t}\n","}\n","\n","int main(int argc, char **argv) {\n","\n","\tint i;\n","\tint N = 1024*1024;\n","\tfloat *samples;\n","\tcufftHandle plan = 0;\n","\tcufftComplex *dComplexSamples, *complexSamples, *complexFreq;\n","\n","\t// Input Generation\n","\trect(N, &samples);\n","\n","  printf(\"Start computation...\\n\");\n","  float start = seconds();\n","\treal_to_complex(samples, &complexSamples, N);\n","\t\n","  complexFreq = (cufftComplex *) malloc(sizeof(cufftComplex) * N);\n","\n","\t// Setup the cuFFT plan\n","\tCHECK_CUFFT(cufftPlan1d(&plan, N, CUFFT_C2C, 1));\n","\n","\t// Allocate device memory\n","\tCHECK(cudaMalloc((void **)&dComplexSamples, sizeof(cufftComplex) * N));\n","\n","\t// Transfer inputs into device memory\n","\tCHECK(cudaMemcpy(dComplexSamples, complexSamples, sizeof(cufftComplex) * N, cudaMemcpyHostToDevice));\n","\n","\t// Execute a complex-to-complex 1D FFT\n","\tCHECK_CUFFT(cufftExecC2C(plan, dComplexSamples, dComplexSamples, CUFFT_FORWARD));\n","\n","\t// Retrieve the results into host memory\n","\tCHECK(cudaMemcpy(complexFreq, dComplexSamples, sizeof(cufftComplex) * N, cudaMemcpyDeviceToHost));\n","\n","  float elaps = seconds() - start;\n","\n","  printf(\"Elapsed time: %f (sec)\\n\", elaps);\n","\n","  // save FFT on a file\n","  printf(\"Save on file...\\n\");\n","  FILE *filePtr;\n","  filePtr = fopen(\"FFTdata.txt\",\"w\");\n","  for (i = 0; i < N; i++) {\n","    fprintf(filePtr, \"%.3g, %.5g\\n\", complexFreq[i].x, complexFreq[i].y);\n","  }\n"," \n","\tfree(samples);\n","\tfree(complexSamples);\n","\tfree(complexFreq);\n","\n","\tCHECK(cudaFree(dComplexSamples));\n","\tCHECK_CUFFT(cufftDestroy(plan));\n","\treturn 0;\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wLxZjCx8bT3s"},"source":["# Compilazione ed esecuzione\n","!nvcc -arch=sm_75 src/cufft.cu -o fft -lcufft\n","!./fft"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uPU4iiE7LT59"},"source":["# python code: read FFT data file and plot the FFT magnitude\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# read file\n","Xlist = [] \n","Ylist = []\n","with open(\"FFTdata.txt\", \"r\") as f:\n","  for line in f.readlines():\n","    x,y = line.split(\",\")\n","    Xlist.append(float(x))\n","    Ylist.append(float(y))\n","\n","# compute magnitude\n","X = np.power(Xlist,2)\n","Y = np.power(Ylist,2)\n","F = np.sqrt(X+Y)\n","\n","# plot\n","plt.subplots(figsize=(10, 6))\n","plt.plot(F[:500])\n","plt.show()"],"execution_count":null,"outputs":[]}]}