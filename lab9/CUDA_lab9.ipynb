{"cells":[{"cell_type":"markdown","metadata":{"id":"GdM-3tzilgXw"},"source":["---\n","# **LAB 9 - CUDA in Python**\n","---"]},{"cell_type":"markdown","metadata":{"id":"WoJbB3T5Vkw-"},"source":["# ‚ñ∂Ô∏è CUDA setup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fht2Wy8wVkxJ"},"outputs":[],"source":["!nvcc --version"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0jP2H_YJVkxJ"},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"markdown","metadata":{"id":"VKbaxH9wWosO"},"source":["[GPU Compute Capability](https://developer.nvidia.com/cuda-gpus)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PNDBUaqqTd66"},"outputs":[],"source":["!git clone https://github.com/giulianogrossi/GPUcomputing.git"]},{"cell_type":"markdown","metadata":{"id":"QadLRsY0hIga"},"source":["# üêç kernel for sum"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aV8uMs78bIBD"},"outputs":[],"source":["from numba import cuda\n","import numpy as np\n","\n","# getting device information\n","cuda.detect();"]},{"cell_type":"code","source":["device = cuda.get_current_device()\n","attribs = [s for s in dir(device) if s.isupper()]        # all attribs\n","for attr in attribs:\n","  print(attr, '=', getattr(device, attr))"],"metadata":{"id":"7MreulpeAwgg"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QrCQalOJm0AC"},"outputs":[],"source":["# CUDA kernels written with `@cuda.jit` do not return values\n","@cuda.jit\n","def add_kernel(x, y, z):\n","  \"\"\"Perform vector sum z = x * y\n","  \"\"\"\n","    \n","  # The actual values of the following CUDA-provided variables for thread and block indices,\n","  # like function parameters, are not known until the kernel is launched.\n","                          \n","  # This Numba-provided convenience function is equivalent to\n","  idx = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\n","\n","  # This calculation gives a unique thread index within the entire grid (see the slides above for more)\n","  # idx = cuda.grid(1)      # 1 = one dimensional thread grid, returns a single value.\n","\n","  # This thread will do the work on the data element with the same index as its own\n","  # unique index within the grid.\n","  z[idx] = x[idx] + y[idx]"]},{"cell_type":"markdown","metadata":{"id":"G-Ou-SvFGiZg"},"source":["Generate data and device setup/transfert..."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dy4bV7iOGmmA"},"outputs":[],"source":["# populate data\n","n = 512*1024*1024\n","print(f'num bytes (3 arrays) = {n*4*3/1024/1024} MB')\n","x = np.arange(n).astype(np.int32) # [0...4095] on the host\n","y = np.ones_like(x)               # [1...1] on the host\n","\n","d_x = cuda.to_device(x) # Copy of x on the device\n","d_y = cuda.to_device(y) # Copy of y on the device\n","d_out = cuda.device_array_like(d_x) # Like np.array_like, but for device arrays"]},{"cell_type":"code","source":["from timeit import default_timer as timer\n","\n","# execution of the kernel\n","start = timer()\n","w = x + y    # sum\n","end = timer()\n","print(f\"Elapsed (sec) = {end - start}\")"],"metadata":{"id":"ryorIpfICf5G"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nPUwTxgiGOrt"},"source":["Define the kernel parameters..."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8Ic-tvzTGMsi"},"outputs":[],"source":["# Because of how we wrote the kernel above, we need to have a 1 thread to one data element mapping,\n","# therefore we define the number of threads in the grid (128*32) to equal n (4096).\n","threads_per_block = 1024\n","blocks_per_grid = int(n/threads_per_block)"]},{"cell_type":"markdown","metadata":{"id":"hYjgy8yNZ3N_"},"source":["launch the kernel..."]},{"cell_type":"code","source":["# execution of the kernel\n","start = timer()\n","add_kernel[blocks_per_grid, threads_per_block](d_x, d_y, d_out)\n","# host and device sync\n","cuda.synchronize()\n","end = timer()\n","print(f\"Elapsed (sec) = {end - start}\")"],"metadata":{"id":"aakmSjwHSTgL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"id":"PJcB-6nTFAUq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["CUDA object..."],"metadata":{"id":"PzCh2_eLHDhV"}},{"cell_type":"code","source":["type(d_x)"],"metadata":{"id":"u6T1x2JaG_fa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Remove the reference from the current namespace"],"metadata":{"id":"rVElVWm1ssKp"}},{"cell_type":"code","source":["del d_x, d_y, d_out\n","del x, y, w"],"metadata":{"id":"POnsr82Hsz1L"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["How to measure performance of NUMBA"],"metadata":{"id":"oh_jt7YA7PPI"}},{"cell_type":"code","source":["from numba import jit\n","import numpy as np\n","import time\n","\n","x = np.arange(100).reshape(10, 10)\n","\n","@jit(nopython=True)\n","def go_fast(a): # Function is compiled and runs in machine code\n","  trace = 0.0\n","  for i in range(a.shape[0]):\n","    trace += np.tanh(a[i, i])\n","  return a + trace\n","\n","# DO NOT REPORT THIS... COMPILATION TIME IS INCLUDED IN THE EXECUTION TIME!\n","start = time.time()\n","go_fast(x)\n","end = time.time()\n","print(\"Elapsed (with compilation) = %s\" % (end - start))\n","\n","# NOW THE FUNCTION IS COMPILED, RE-TIME IT EXECUTING FROM CACHE\n","start = time.time()\n","go_fast(x)\n","end = time.time()\n","print(\"Elapsed (after compilation) = %s\" % (end - start))"],"metadata":{"id":"Tf3b05qD6xOG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D-xki0BeGIOY"},"source":["# üêç Mat multiplication kernel"]},{"cell_type":"markdown","source":["A tutorial that explains NumPy axes: [Numpy axes](https://www.sharpsightlabs.com/blog/numpy-axes-explained/)"],"metadata":{"id":"bTMtXizJ-lVQ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"FBRTfOF5BIAK"},"outputs":[],"source":["from numba import cuda\n","import time\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vzoVtm6O61DL"},"outputs":[],"source":["@cuda.jit\n","def matmul(A, B, C):\n","  \"\"\"Perform square matrix multiplication of C = A * B.\"\"\"\n","  i, j = cuda.grid(2)\n","  if i < C.shape[0] and j < C.shape[1]:\n","    tmp = 0.\n","    for k in range(A.shape[1]):\n","      tmp += A[i, k] * B[k, j]\n","    C[i, j] = tmp\n","\n","# matrix multiplication using the cpu and C-like programming style (** strongly discouraged **)\n","def matmul_cpu(A, B):\n","  \"\"\"\n","  Perform square matrix multiplication of C = A * B\n","  \"\"\"\n","  C = np.zeros((A.shape[1],B.shape[1]))\n","  for i in range(A.shape[1]):\n","    for j in range(B.shape[0]):\n","      tmp = 0.                            \n","      for k in range(A.shape[1]):\n","        tmp += A[i, k] * B[k, j]   # multiply elements in row i of A and column j of B and add to temp\n","      C[i, j] = tmp    "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IGEoEUjo683n"},"outputs":[],"source":["# generate random vals\n","np.random.seed(42)\n","SIZE = 8000\n","A = np.ones((SIZE,SIZE)).astype('float32')  # mat 1\n","B = np.ones((SIZE,SIZE)).astype('float32')  # mat 2\n","#C = np.zeros((SIZE,SIZE)).astype('float32')                       # mat where we store answer \n","\n","d_A = cuda.to_device(A) # Copy of A on the device\n","d_B = cuda.to_device(B) # Copy of B on the device\n","d_C = cuda.device_array_like(A) # malloc on the device\n","\n","# data type\n","d_A.dtype"]},{"cell_type":"markdown","metadata":{"id":"zgJRscuQhrs4"},"source":["Kernel parameters..."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tlBglj4fGVCT"},"outputs":[],"source":["block = (32, 32)  # each block will contain 32x32 threads, typically 128 - 512 threads/block\n","grid_x = int(np.ceil(A.shape[0] / block[0]))\n","grid_y = int(np.ceil(A.shape[1] / block[1]))\n","grid = (grid_x, grid_y)  # we calculate the gridsize (number of blocks) from array\n","print(grid)\n","print(f\"The kernel will be executed up to element {block[0]*grid_x}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ec9uXEHSGiex"},"outputs":[],"source":["# execution of the kernel\n","start = time.time()\n","matmul[grid, block](d_A, d_B, d_C)\n","# host and device sync\n","cuda.synchronize()\n","end = time.time()\n","print(\"Elapsed (sec) = %s\" % (end - start))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7P7nxI9beoPD"},"outputs":[],"source":["C = d_C.copy_to_host()\n","print(C)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MNkQpD0XJ1mS"},"outputs":[],"source":["%%time\n","# execution of the python function in C-like programming style (strongly discouraged!)\n","D = matmul_cpu(A, B)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gKK5r5tbL8Z9"},"outputs":[],"source":["# using numpy function\n","start = time.time()\n","C = np.dot(A, B)\n","end = time.time()\n","print(\"Elapsed (sec) = %s\" % (end - start))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qigD6_LKgpOr"},"outputs":[],"source":["print(C)"]},{"cell_type":"markdown","source":["# üî¥ TODO"],"metadata":{"id":"QZk-KeLSuLC7"}},{"cell_type":"markdown","source":["Improved matrix multiplication usin SMEM\n","\n","```\n","# Controls threads per block and shared memory usage.\n","# The computation will be done on blocks of TPBxTPB elements.\n","# TPB should not be larger than 32 in this example\n","TPB = 16\n","@cuda.jit\n","def fast_matmul(A, B, C):\n","\n","  # Define an array in the shared memory\n","\n","  # Each thread computes one element in the result matrix.\n","\n","  # Wait until all threads finish preloading\n","\n","  # Computes partial product on the shared memory\n","\n","  # Wait until all threads finish computing\n","```\n","\n"],"metadata":{"id":"YxInoGfX_vhm"}},{"cell_type":"code","source":["# Controls threads per block and shared memory usage.\n","# The computation will be done on blocks of TPBxTPB elements.\n","# TPB should not be larger than 32 in this example\n","TPB = 16\n","\n","@cuda.jit\n","def fast_matmul(A, B, C):\n","    # Define an array in the shared memory\n","    # The size and type of the arrays must be known at compile time\n","    sA = cuda.shared.array(shape=(TPB, TPB), dtype=np.float32)\n","    sB = cuda.shared.array(shape=(TPB, TPB), dtype=np.float32)\n","\n","    x, y = cuda.grid(2)\n","\n","    tx = cuda.threadIdx.x\n","    ty = cuda.threadIdx.y\n","    bpg = cuda.gridDim.x    # blocks per grid\n","\n","    if x >= C.shape[0] and y >= C.shape[1]:\n","        # Quit if (x, y) is outside of valid C boundary\n","        return\n","\n","    # Each thread computes one element in the result matrix.\n","    # The dot product is chunked into dot products of TPB-long vectors.\n","    tmp = 0.\n","    for i in range(bpg):\n","        # Preload data into shared memory\n","        sA[tx, ty] = A[x, ty + i * TPB]\n","        sB[tx, ty] = B[tx + i * TPB, y]\n","\n","        # Wait until all threads finish preloading\n","        cuda.syncthreads()\n","\n","        # Computes partial product on the shared memory\n","        for j in range(TPB):\n","            tmp += sA[tx, j] * sB[j, ty]\n","\n","        # Wait until all threads finish computing\n","        cuda.syncthreads()\n","\n","    C[x, y] = tmp"],"metadata":{"id":"JjMHZ0mzuNP0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# generate random vals\n","np.random.seed(42)\n","SIZE = 8000\n","A = np.ones((SIZE,SIZE)).astype('float32')  # mat 1\n","B = np.ones((SIZE,SIZE)).astype('float32')  # mat 2\n","#C = np.zeros((SIZE,SIZE)).astype('float32')                       # mat where we store answer \n","\n","d_A = cuda.to_device(A) # Copy of A on the device\n","d_B = cuda.to_device(B) # Copy of B on the device\n","d_C = cuda.device_array_like(A) # malloc on the device\n","\n","# data type\n","d_A.dtype"],"metadata":{"id":"PQUK-YL_nCME"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Bdk-X-IGFkRy"},"source":["Kernel parameters..."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kfG-ZIx8FkR7"},"outputs":[],"source":["block = (TPB, TPB)  # each block will contain TPBxTPB threads, typically 128 - 512 threads/block\n","grid_x = int(np.ceil(A.shape[0] / block[0]))\n","grid_y = int(np.ceil(A.shape[1] / block[1]))\n","grid = (grid_x, grid_y)  # we calculate the gridsize (number of blocks) from array\n","print(grid)\n","print(f\"The kernel will be executed up to element {block[0]*grid_x}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nyKBAhv0FkR7"},"outputs":[],"source":["# execution of the kernel\n","start = time.time()\n","fast_matmul[grid, block](d_A, d_B, d_C)\n","\n","# host and device sync\n","cuda.synchronize()\n","end = time.time()\n","print(\"Elapsed (sec) = %s\" % (end - start))"]},{"cell_type":"markdown","metadata":{"id":"m0phl-Kp-IpW"},"source":["# üêç Histogram"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"39smdj2hlvE4"},"outputs":[],"source":["from numba import cuda\n","import numpy as np"]},{"cell_type":"markdown","metadata":{"id":"4w-eKaICUut7"},"source":["## üî¥ TODO"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cmge3NGnNkfb"},"outputs":[],"source":["@cuda.jit\n","def BMP_hist(I, hist):\n","  '''\n","  Increment bin counts in hist\n","    params:\n","      - I (uint8)  : HxWx3 matrix\n","      - hist (int) : 256x3 matrix\n","  '''\n","\n","  i, j = cuda.grid(2)  \n","  R = I[i,j,0]\n","  G = I[i,j,1]\n","  B = I[i,j,2]\n","  cuda.atomic.add(hist[0], R, 1)\n","  cuda.atomic.add(hist[1], G, 1)\n","  cuda.atomic.add(hist[2], B, 1)"]},{"cell_type":"markdown","metadata":{"id":"LEhX3FMsU4wZ"},"source":["## Gestione immagine e kernel..."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SFEoj0hudWKT"},"outputs":[],"source":["from PIL import Image\n","\n","#image.save('beach1.bmp')\n","img = Image.open('GPUcomputing/images/dog.bmp')\n","img_rgb = img.convert('RGB')\n","img_rgb"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H6KKuOF0-J0Z"},"outputs":[],"source":["# converto to numpy (host)\n","I = np.asarray(img)\n","print(f\"Image size W x H x ch = {I.shape}\")\n","\n","# device data setup\n","d_I = cuda.to_device(I)\n","H = np.zeros((3,256)).astype(np.float32)\n","d_H = cuda.to_device(H)"]},{"cell_type":"markdown","metadata":{"id":"YKvOMIuuiEY6"},"source":["Kernel parameters..."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Of0_Z_U-h7r0"},"outputs":[],"source":["block = (16, 16)  # each block will contain 16x16 threads, typically 128 - 512 threads/block\n","grid_x = int(np.ceil(I.shape[0] / block[0]))\n","grid_y = int(np.ceil(I.shape[1] / block[1]))\n","grid = (grid_x, grid_y)  # we calculate the gridsize (number of blocks) from array\n","print(grid)\n","print(f\"The kernel will be executed up to element {block[0]*grid_x}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xSPvkDBhU7wD"},"outputs":[],"source":["# kernel launch\n","\n","BMP_hist[grid, block](d_I, d_H)\n","hist = d_H.copy_to_host()\n","print(hist.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aPfeWSylWPRQ"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","plt.bar(np.arange(256),hist[0])\n","plt.title('Histogram (R)')\n","plt.show()\n","plt.bar(np.arange(256),hist[1])\n","plt.title('Histogram (G)')\n","plt.show()\n","plt.bar(np.arange(256),hist[2])\n","plt.title('Histogram (B)')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"qksYnBHcuJGi"},"source":["# üî¥ TODO"]},{"cell_type":"markdown","metadata":{"id":"OO6JAs2hubiH"},"source":["Calcolare il prodotto di matrici MQDB con kernel CUDA in Python"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j_LB5W3iQ0IR"},"outputs":[],"source":["from numba import cuda\n","import numpy as np\n","import time\n","\n","def MQDB_gen(n, k, values=None):\n","  \"\"\"\n","  Generate a random MQDB of size n with k (random sized) blocks\n","    params:\n","      n (int)                : mat size\n","      k (int or list)        : the number of blocks or blocks dims (list)\n","      values (string or num) : the string 'rand' for random values, \n","                               a scalar for constant values everywere,\n","                               'None' for no assignement        \n","  \"\"\"\n","  # blocks dims\n","  if isinstance(k, (list, np.ndarray)):\n","    blkdims = k  # list of already defined dims\n","  else:          # generate new dims\n","    bins = np.concatenate((np.ones(n), np.zeros(n*(k-1))))\n","    np.random.shuffle(bins)\n","    blkdims = np.sum(bins.reshape(k,n),axis=1).astype('int')\n","  print(f\"Mat size n = {n}  --  num blocks k = {blkdims.shape[0]}\")\n","  print('Blocks dims = ', blkdims)\n","  \n","  A = np.zeros((n,n))\n","  # filling of blocks \n","  if values is not None:\n","    end = 0\n","    for b in blkdims:\n","      start = end\n","      end = end + b\n","      if values == 'rand':\n","        A[start:end,start:end] = np.random.rand(b,b)\n","      else:\n","        A[start:end,start:end] = values*np.ones(b,b)\n","      \n","  # return final data\n","  return A, blkdims\n","\n","@cuda.jit\n","def matmul_MQDB(A, B, C, blkdim, blksum):\n","  \"\"\"\n","  Perform MQDB matrix multiplication C = A * B\n","  params:\n","      A,B,C (MQDB) : omogeneous MQDB types \n","      blkdim (int) : the current block dim\n","      blksum (int) : sum of the previous blocks sizes    \n","  \"\"\"\n","  row, col = cuda.grid(2)\n","  if row < blkdim and col < blkdim:\n","    tmp = 0.\n","    for k in range(blkdim):\n","      tmp += A[row+blksum, k+blksum] * B[k+blksum, col+blksum]\n","    C[row+blksum, col+blksum] = tmp\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NIimRLkTV44r"},"outputs":[],"source":["# generate random blocks and data\n","n = 10000\n","k = 4\n","A, blkdims = MQDB_gen(n, k, values=1)\n","B, _ = MQDB_gen(n, blkdims, values=1)\n","C, _ = MQDB_gen(n, blkdims)\n","\n","# device mem\n","d_A = cuda.to_device(A) # Copy of A on the device\n","d_B = cuda.to_device(B) # Copy of B on the device\n","d_C = cuda.device_array_like(A) # malloc on the device"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JDRKviEMWM88"},"outputs":[],"source":["# run the kernels\n","\n","# warm up \n","matmul_MQDB[grid, block](d_A, d_B, d_C, blkdims[0], 0)\n","\n","start = time.time()\n","block = (16, 16) # block size\n","for i in range(k):\n","  grid_x = int(np.ceil(blkdims[i]/block[0]))\n","  grid_y = int(np.ceil(blkdims[i]/block[1]))\n","  grid = (grid_x, grid_y)  \n","  sum_blks = 0 if i==0 else np.sum(blkdims[0:i])\n","  # kernel launch\n","  matmul_MQDB[grid, block](d_A, d_B, d_C, blkdims[i], sum_blks)\n","\n","# host and device sync\n","cuda.synchronize()\n","end = time.time()\n","print(\"Elapsed (sec) = %s\" % (end - start))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yiFFAQ6CYEzw"},"outputs":[],"source":["# print results\n","print('results: matrx C')\n","import sys\n","C = d_C.copy_to_host() # copy to host from device\n","print(C)"]},{"cell_type":"code","source":["# using numpy function\n","\n","start = time.time()\n","np.dot(A,B)\n","end = time.time()\n","print(\"Elapsed (sec) = %s\" % (end - start))"],"metadata":{"id":"a0WiSJUIuNpP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# üêç Pseudo-random generator"],"metadata":{"id":"bXV219hemCEo"}},{"cell_type":"code","source":["from __future__ import print_function, absolute_import\n","\n","from numba import cuda\n","from numba.cuda.random import create_xoroshiro128p_states, xoroshiro128p_uniform_float32\n","import numpy as np\n","\n","@cuda.jit\n","def compute_pi(rng_states, iterations, out):\n","    \"\"\"Find the maximum value in values and store in result[0]\"\"\"\n","    thread_id = cuda.grid(1)\n","\n","    # Compute pi by drawing random (x, y) points and finding what\n","    # fraction lie inside a unit circle\n","    inside = 0\n","    for i in range(iterations):\n","        x = xoroshiro128p_uniform_float32(rng_states, thread_id)\n","        y = xoroshiro128p_uniform_float32(rng_states, thread_id)\n","        if x**2 + y**2 <= 1.0:\n","            inside += 1\n","\n","    out[thread_id] = 4.0 * inside / iterations\n","\n","####### run ######\n","threads_per_block = 64\n","blocks = 24\n","rng_states = create_xoroshiro128p_states(threads_per_block * blocks, seed=1)\n","out = np.zeros(threads_per_block * blocks, dtype=np.float32)\n","compute_pi[blocks, threads_per_block](rng_states, 10000, out)\n","print('pi:', out.mean())"],"metadata":{"id":"kliqy1wPmBji"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a new stream\n","stream = cuda.stream()\n","# Create a pinned array on the host for async transfers\n","a = cuda.pinned_array(n, dtype=np.int32)\n","# Create an array with a \"default stream‚Äú\n","d_a = cuda.device_array_like(a, stream)\n","# Numba automatically uses async transfers when streams involvedd_a.copy_to_device(a, stream=stream)\n","# Kernel launch on stream\n","kernel[nblocks, nthreads, stream]"],"metadata":{"id":"HYdWloSPJDDj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# üêç Fractals"],"metadata":{"id":"myfjpgCcYY-0"}},{"cell_type":"code","source":["from __future__ import print_function, division, absolute_import\n","\n","from timeit import default_timer as timer\n","from matplotlib.pylab import imshow, show\n","import numpy as np\n","\n","from numba import jit\n","\n","@jit\n","def mandel(x, y, max_iters):\n","    \"\"\"\n","    Given the real and imaginary parts of a complex number,\n","    determine if it is a candidate for membership in the Mandelbrot\n","    set given a fixed number of iterations.\n","    \"\"\"\n","    i = 0\n","    c = complex(x, y)\n","    z = 0.0j\n","    for i in range(max_iters):\n","        z = z * z + c\n","        if (z.real * z.real + z.imag * z.imag) >= 4:\n","            return i\n","\n","    return 255\n","\n","\n","@jit\n","def create_fractal(min_x, max_x, min_y, max_y, image, iters):\n","    height = image.shape[0]\n","    width = image.shape[1]\n","\n","    pixel_size_x = (max_x - min_x) / width\n","    pixel_size_y = (max_y - min_y) / height\n","    for x in range(width):\n","        real = min_x + x * pixel_size_x\n","        for y in range(height):\n","            imag = min_y + y * pixel_size_y\n","            color = mandel(real, imag, iters)\n","            image[y, x] = color\n","\n","    return image\n","\n","###### run MANDEL-CPU code #########\n","\n","width = 15000\n","height = 10000\n","image = np.zeros((height, width), dtype=np.uint8)\n","\n","s = timer()\n","create_fractal(-2.0, 1.0, -1.0, 1.0, image, 20)\n","e = timer()\n","print(\"Execution time: %f seconds\" % (e - s))\n","\n","imshow(image)\n","show()"],"metadata":{"id":"N8SGhOIJaBZD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from __future__ import print_function, division, absolute_import\n","\n","from timeit import default_timer as timer\n","from matplotlib.pylab import imshow, show\n","import numpy as np\n","\n","from numba import cuda\n","\n","\n","@cuda.jit(device=True)\n","def mandel(x, y, max_iters):\n","  \"\"\"\n","  Given the real and imaginary parts of a complex number,\n","  determine if it is a candidate for membership in the Mandelbrot\n","  set given a fixed number of iterations.\n","  \"\"\"\n","  i = 0\n","  c = complex(x, y)\n","  z = 0.0j\n","  for i in range(max_iters):\n","    z = z * z + c\n","    if (z.real * z.real + z.imag * z.imag) >= 4:\n","      return i\n","\n","  return 255\n","\n","\n","@cuda.jit\n","def create_fractal(min_x, max_x, min_y, max_y, image, iters):\n","  height = image.shape[0]\n","  width = image.shape[1]\n","\n","  pixel_size_x = (max_x - min_x) / width\n","  pixel_size_y = (max_y - min_y) / height\n","\n","  x, y = cuda.grid(2)\n","\n","  if x < width and y < height:\n","    real = min_x + x * pixel_size_x\n","    imag = min_y + y * pixel_size_y\n","    color = mandel(real, imag, iters)\n","    image[y, x] = color\n","\n","\n","###### run MENDEL-GPU code #########\n","\n","width = 15000\n","height = 10000\n","image = np.zeros((height, width), dtype=np.uint8)\n","\n","pixels = width * height\n","nthreads = 32\n","nblocksy = (height // nthreads) + 1\n","nblocksx = (width // nthreads) + 1\n","s = timer()\n","\n","create_fractal[(nblocksx, nblocksy), (nthreads, nthreads)](-2.0, 1.0, -1.0, 1.0, image, 20)\n","cuda.synchronize()\n","e = timer()\n","print(\"Execution time: %f seconds\" % (e - s))\n","\n","imshow(image)\n","show()"],"metadata":{"id":"iuUpMx5SYW0w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from numpy import newaxis\n","\n","def compute_mandelbrot(N_max, some_threshold, nx, ny):\n","    # A grid of c-values\n","    x = np.linspace(-2, 1, nx)\n","    y = np.linspace(-1.5, 1.5, ny)\n","\n","    c = x[:,newaxis] + 1j*y[newaxis,:]\n","\n","    # Mandelbrot iteration\n","\n","    z = c\n","\n","    # The code below overflows in many regions of the x-y grid, suppress\n","    # warnings temporarily\n","    with np.warnings.catch_warnings():\n","        np.warnings.simplefilter(\"ignore\")\n","        for j in range(N_max):\n","            z = z**2 + c\n","        mandelbrot_set = (abs(z) < some_threshold)\n","\n","    return mandelbrot_set\n","\n","mandelbrot_set = compute_mandelbrot(1000, 1., 1000,1000)\n","\n","plt.imshow(mandelbrot_set.T)\n","\n","plt.show()"],"metadata":{"id":"n7Oq7tZBYakT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Numpy and CPU\n","s = time.time()\n","x_cpu *= 5\n","e = time.time()\n","print(f\"CPU: {e-s}\")\n","\n","### CuPy and GPU\n","s = time.time()\n","x_gpu *= 5\n","cp.cuda.Stream.null.synchronize()\n","e = time.time()\n","print(f\"GPU: {e-s}\")"],"metadata":{"id":"JAnklGBAMVVT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# ‚úÖ CuPy"],"metadata":{"id":"l1rqW0qCN4YD"}},{"cell_type":"markdown","metadata":{"id":"n7s0fNhj8MK5"},"source":["Basics of CuPy\n","In this section, you will learn about the following things:\n","\n","- Basics of cupy.ndarray\n","\n","- The concept of current device\n","\n","- Host-device and device-device array transfer\n","\n"]},{"cell_type":"markdown","metadata":{"id":"eTnzYTT-8Ydu"},"source":["CuPy is a GPU array backend that implements a subset of NumPy interface. In the following code, `cp` is an abbreviation of `cupy`, following the convention of abbreviating `numpy` to `np`:"]},{"cell_type":"code","metadata":{"id":"Vwk0mIU260-T"},"source":["import numpy as np\n","import cupy as cp\n","import time"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HskcLFHP8a9f"},"source":["The `cupy.ndarray` class is in its core, which is a compatible GPU alternative of `numpy.ndarray`."]},{"cell_type":"code","metadata":{"id":"EW7Juf-265nJ"},"source":["x_gpu = cp.array([1, 2, 3])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7GnwT-3X8vRG"},"source":["`x_gpu` in the above example is an instance of `cupy.ndarray`. You can see its creation of identical to NumPy‚Äôs one, except that `numpy` is replaced with `cupy`. The main difference of `cupy.ndarray` from `numpy.ndarray` is that the content is allocated on the device memory. Its data is allocated on the current device, which will be explained later.\n","\n","Most of the array manipulations are also done in the way similar to NumPy. Take the Euclidean norm (a.k.a L2 norm) for example. NumPy has `numpy.linalg.norm()` to calculate it on CPU."]},{"cell_type":"code","metadata":{"id":"w9JcohVT81HS"},"source":["x_cpu = np.array([1, 2, 3])\n","l2_cpu = np.linalg.norm(x_cpu)\n","print(l2_cpu)\n","\n","x_gpu = cp.array([1, 2, 3])\n","l2_gpu = cp.linalg.norm(x_gpu)\n","print(l2_gpu)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ViTanoJN9I0_"},"source":["CuPy has a concept of current devices, which is the default device on which the allocation, manipulation, calculation, etc., of arrays are taken place. Suppose the ID of current device is 0. The following code allocates array contents on GPU 0."]},{"cell_type":"code","metadata":{"id":"iBg3heve9PCq"},"source":["x_on_gpu0 = cp.array([1, 2, 3, 4, 5])\n","# cp.cuda.Device(1).use() # trigger dev 1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Q7drGpfb9wCU"},"source":["__Move arrays to a device__ \n","\n","`cupy.asarray()` can be used to move a `numpy.ndarray`, a `list`, or any `object` that can be passed to `numpy.array()` to the current device:"]},{"cell_type":"code","metadata":{"id":"KvD5Dc9r923D"},"source":["x_cpu = np.array([1, 2, 3])\n","x_gpu = cp.asarray(x_cpu)  # move the data to the current device."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PXUrXI0T-ESO"},"source":["`cupy.asarray()` can accept `cupy.ndarray`, which means we can transfer the array between devices with this function."]},{"cell_type":"markdown","metadata":{"id":"XsUNmrVt-egt"},"source":["__Move array from a device to the host__\n","\n","Moving a device array to the host can be done by `cupy.asnumpy()` as follows:"]},{"cell_type":"code","metadata":{"id":"7HCC9Xot-jfO"},"source":["x_gpu = cp.array([1, 2, 3])  # create an array in the current device\n","x_cpu = cp.asnumpy(x_gpu)  # move the array to the host.\n","\n","# We can also use cupy.ndarray.get():\n","x_cpu = x_gpu.get()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ya5ZUuX5_Qyi"},"source":["__How to write CPU/GPU agnostic code__\n","\n","The compatibility of CuPy with NumPy enables us to write CPU/GPU generic code. It can be made easy by the `cupy.get_array_module()` function. This function returns the numpy or cupy module based on arguments. A CPU/GPU generic function is defined using it like follows:\n","\n"]},{"cell_type":"code","metadata":{"id":"m41F-1Tu_UQz"},"source":["# Stable implementation of log(1 + exp(x))\n","def softplus(x):\n","  xp = cp.get_array_module(x)\n","  return xp.maximum(0, x) + xp.log1p(xp.exp(-abs(x)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lFq4cQEM_lBL"},"source":["Sometimes, an explicit conversion to a host or device array may be required. `cupy.asarray()` and `cupy.asnumpy()` can be used in agnostic implementations to get host or device arrays from either CuPy or NumPy arrays."]},{"cell_type":"code","metadata":{"id":"BjpD_S2pACgb"},"source":["y_cpu = np.array([4, 5, 6])\n","x_cpu + y_cpu\n","x_gpu + y_cpu"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J_FzwiWg_ogl"},"source":["cp.asnumpy(x_gpu) + y_cpu\n","cp.asnumpy(x_gpu) + cp.asnumpy(y_cpu)\n","x_gpu + cp.asarray(y_cpu)\n","cp.asarray(x_gpu) + cp.asarray(y_cpu)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Cupy demo"],"metadata":{"id":"WcfingSvOvQN"}},{"cell_type":"markdown","source":["* CuPy implements the multi-dimensional array of numpy on CUDA.\n","* CuPy has a large community of developers (on github),\n","under the direction by the company Preferred Networks.\n","* CuPy uses on-the-fly kernel synthesis:\n","for a required kernel call, it compiles the code of the kernel,\n","optimizes for shapes and dtypes of the arguments;\n","sends the compiled code to the GPU device; and\n","executes the kernel.\n","* The kernel code is cached, so the second call executes faster."],"metadata":{"id":"xWEf8_LOQfT7"}},{"cell_type":"code","source":["### Numpy and CPU\n","s = time.time()\n","x_cpu = np.ones((1000,1000,1000))\n","e = time.time()\n","print(f\"CPU: {e-s}\")\n","\n","### CuPy and GPU\n","s = time.time()\n","x_gpu = cp.ones((1000,1000,1000))\n","cp.cuda.Stream.null.synchronize()\n","e = time.time()\n","print(f\"GPU: {e-s}\")"],"metadata":{"id":"lENNIpGJMP1x"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1vaU1C6sX3ML8Xv7r-nCraOSLNbW1G0I6","timestamp":1684146791256},{"file_id":"15IDLiUMRJbKqZUZPccyigudINCD5uZ71","timestamp":1647557168268}],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}